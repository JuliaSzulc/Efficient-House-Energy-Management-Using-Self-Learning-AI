{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch - o co chodzi?\n",
    "\n",
    "#### Uwaga: nie edytujcie i nie odpalajcie komórek z kodem. Są tylko dla przykładu i się nie wykonają."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przede wszystkim, PyTorch wprowadza:\n",
    "\n",
    "- n-wymiarową strukturę Tensor, praktcznie identyczna do numpy'owej 'ndarray',\n",
    "ale z supportem dla obliczeń na GPU\n",
    "\n",
    "- Automatyczne różniczkowanie, które pozwala bardzo uprościć zapis liczenia\n",
    "gradientów i aktualizacji parametrów sieci neuronowych\n",
    "\n",
    "- moduły takie jak torch.nn czy torch.F, zawierające gotowe klasy i metody do\n",
    "budowania sieci (np. gotowe 'layery', funkcje aktywacji)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Prerekwizyty\n",
    "\n",
    "Warto byłoby wcześniej wiedzieć chociaż minimalnie o:\n",
    "- Numpy. Co to ndarray, podstawowe operacje, jak można wybierać z tych struktur dane.\n",
    "- Sieci neuronowe - jak wygląda forward pass, o co chodzi w backpropagation (opcjonalnie)\n",
    "- Co to gradient, a co to pochodna cząstkowa, ważne, żeby to rozróżniać, bo często używa się jako skrót myślowy jednego zwrotu zamiast drugiego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tensory\n",
    "\n",
    "Podstawowe 'twory' PyTorcha, którymi posługujemy się tak, jak ndarray's, ale\n",
    "w łatwy sposób możemy używać GPU do obliczeń z nimi związanych.\n",
    "\n",
    "- Tensory nic nie wiedzą o deep learning, pochodnych itd. Zamysł twórców jest taki, że można używać PyTorcha i Tensorów do innych rzeczy, w których jest dużo operacji macierzowych, a deep learning to tylko jedno z zastosowań, dla którego istnieje cała reszta modułów.\n",
    "\n",
    "- Większość operacji można robić na 2 sposoby\n",
    "\n",
    "(x i y to Tensory, za add można tu wstawić w zasadzie wszystkie tego typu operacje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note - przykłady w kodzie są read-only, nie wykonają się w notebooku, nie ma importów itd.\n",
    "\n",
    "torch.add(x, y)\n",
    "x.add_(y) # zmienia in-place\n",
    "x.add(y)  # zwraca nowy tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Numpy bridges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z numpy do tensora:\n",
    "y = torch.from_numpy(x)\n",
    "\n",
    "# z tensora do numpy:\n",
    "z = y.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wszystkie operacje (docs bez którego nie przetrwa nikt podczas pisania kodu PyTorch :D):\n",
    "\n",
    "http://pytorch.org/docs/master/torch.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd i Variables\n",
    "http://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeden wrapper dla twórców PyTorcha to za mało, więc zrobili jeszcze wrapper\n",
    "na Tensory - Variable z pakietu autograd:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.autograd.Variable(torch.FloatTensor(np.array([0.1, 0.2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd to moduł odpowiadający za automatyczne liczenie pochodnych.\n",
    "Dla zarejestrowanej Variable 'zapamiętuje' historię operacji, które brały udział w jej stworzeniu w postaci grafu.\n",
    "\n",
    "### Każda Variable posiada pola:\n",
    "- .data - x.data zwraca tensor z danymi jakie 'opakowuje'\n",
    "- .grad - wartość gradientu dla tej zmiennej\n",
    "- .grad_fn - funkcja która utworzyła tę zmienną. Jeżeli user tworzy sam nową zmienną, to jest to None, jeżeli np. dodano dwie inne zmienne, aby otrzymać tę zmienną, to jest to funkcja dodawania itd. \n",
    "- ! Uwaga - ta funkcja (jest to ofc jakiś obiekt) ma w środku oczywiście odwołania do zmiennych, które były parametrami tej funkcji, więc może z nich odczytać funkcje tworzące te parametry - powstaje taka 'rekurencja' której wynikiem może być cały 'graf'\n",
    "\n",
    "### Jak tego używać?\n",
    "\n",
    "Gdy rejestrujemy/tworzymy zmienne, to po to, aby wykorzystać je do obliczenia jakiejś wartości - <b>u nas to będzie 'loss'</b>, wartość funkcji która mówi jak bardzo nasza sieć 'nie ma racji'. \n",
    "<b>Chcemy minimalizować tę funkcję</b>.\n",
    "\n",
    "- Po pewnych obliczeniach - u nas związanych z alg. Q-Learning - otrzymujemy Variable 'loss'\n",
    "- PyTorch trzyma całą 'historię' operacji, które były potrzebne do otrzymania tej wartości (możemy sobie wręcz wyobrazić, że trzyma taki jeden, końcowy duży wzór na funkcję loss, gdzie zmiennymi są wszystkie wartości, których użyliśmy po drodze) \n",
    "- Wykonując loss.backward(), wywołujemy wewnętrzny mechanizm, który oblicza nam gradient, czyli pochodne cząstkowe względem wszystkich parametrów, które brały udział w obliczeniu tej funkcji.\n",
    "- Każda Variable, która brałą udział w obliczeniu loss, ma teraz w polu .grad nową wartość - <b>wartość pochodnej cząstkowej tego 'finalnego wzoru' względem tej Variable</b>\n",
    "\n",
    "Czyli przykładowo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Variable(torch.Tensor(np.array([0.5])))\n",
    "x = w * w\n",
    "y = Variable(torch.Tensor(np.array([2.0])))\n",
    "\n",
    "z = x*y\n",
    "\n",
    "z.backward()\n",
    "\n",
    "# z = x * y = w^2 * y\n",
    "# pochodna cząstkowa 'funkcji' z po parametrze w jest równa 2w * y, czyli 1.0 * 2.0 = 2.0\n",
    "# pochodna cząstkowa z po parametrze x równa jest y, czyli 2.0\n",
    "# pochodna cząstkowa z po parametrze y równa jest x, czyli 1.0\n",
    "# zatem:\n",
    "# w.grad = [2.0]\n",
    "# x.grad = [2.0] (to jest Variabler, a nie pojedyńcza liczba, bo w domyśle x i y to mogą być macierze ofc, \n",
    "                # przykład jest dla 1-elemtowych 1d Variables)\n",
    "# y.grad = [1.0]\n",
    "\n",
    "# Uwaga - tak naprawdę to domyślnie nic się nie zmieni w polach grad - patrz niżej!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Co nam to daje? Jeżeli zarejestrowanymi zmiennymi były wagi i biasy sieci neuronowej,\n",
    "to dzieki .backward() mamy obliczony gradient, w kierunku którego aktualizujemy wartości\n",
    "tych parametrów, 'ulepszając sieć'.\n",
    "\n",
    "### Dodatkowo: tworząc zmienną, można powiedzieć parametrem, czy chcemy, aby pytorch liczył dla niej gradient (domyślnie FALSE!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Variable(tensor1, requires_grad=True)\n",
    "x = Variable(tensor2, requires_grad=False)\n",
    "\n",
    "Z = x + y\n",
    "\n",
    "Z.backward() # y.grad zostanie zaktualizowane, x.grad nie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moduł nn - neural netowork\n",
    "\n",
    "- Moduł ten korzysta z modułu autograd, aby definiowane modele były łatwe w obsłudze jeżeli chodzi o proces uczenia. Dokładniej - my nie tworzymy bezpośrednio Variables które są wagami i biasami sieci - to dzieje się pod spodem - <b>i co ważne - te parametry są tworzone z flagą requires_grad=True</b>\n",
    "\n",
    "- Poniżej prosta definicja sieci z hidden layerem. Jak widać wykorzystujemy moduł nn do prostej definicji layerów np. Linear (używamy tych layerów jak funkcje! np. x = self.fc1(x)), oraz modułu F do różnego rodzaju funkcji aktywacji na poszczególnych warstwach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\" Prosta sieć w PyTorch (3-layer)\n",
    "    \"\"\"\n",
    "    def __init__(self, i_size, h_size, o_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(i_size, h_size)\n",
    "        self.fc2 = nn.Linear(h_size, o_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mamy sieć, wiemy coś o Variable i aurograd. Jak uczyć?\n",
    "\n",
    "- Brakuje nam jeszcze jednej rzeczy. Załóżmy, że mamy zdefiniowaną sieć, przekazaliśmy input ze zbioru uczącego, na podstawie wyniku i wartości oczekiwanej mamy policzony loss, a z loss.backward() jest policzony gradient.\n",
    "\n",
    "- Musimy teraz zaktualizować parametry zgodnie z tym gradientem. \n",
    "\n",
    "- Możemy to zrobić Pythonowo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate) # jak widać f.grad to Variable, \n",
    "                                             # więc wołamy .data przed operacją, aby 'wyłuskać' tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ale PyTorch ma jeszcze jedną świetną część. Jest to moduł <b>optim</b>,  który pozwala na przeprowadzanie tych aktualizacji automatycznie, a co więcej, zgodnie z różnymi algorytmami opracowanymi przez badaczy. Ten powyżej wykorzystuje stałe learning_rate, a istnieje wiele metodyk obniżania/dostosowywania tego parametru wraz z uczeniem się, np. Adam, Adagrad itd. \n",
    "- Przykładowo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "# optimizer = optim.Adam(net.parameters()) itd. itp.\n",
    "\n",
    "optimizer.zero_grad()               # zerowanie gradientu\n",
    "output = net(input)                 # forward pass sieci\n",
    "loss = criterion(output, target)    # obliczenie loss\n",
    "loss.backward()                     # obliczamy gradient\n",
    "optimizer.step()                    # aktualizujemy parametry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uwaga: Warto zauważyć, że .backward() nie ustala wartości .grad na nowo, tylko 'appenduje', dodając do obecnej wartości nowy gradient, więc przed każdą nową iteracją optimizer.zero_grad() resetuje te wartości. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TBC - bardziej skomplikowane operacje na Tensorach, jak rozumieć ich size, operacje z parametrem dim, gather(), squeeze() itd."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
